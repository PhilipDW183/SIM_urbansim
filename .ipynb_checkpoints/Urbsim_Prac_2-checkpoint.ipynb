{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dr Dennett's Guide to Spatial Interaction Modelling  -  Part 2: Constrained Models \n",
    "Code translated to Python by Philip Wilkinson\n",
    "## Recap\n",
    "\n",
    "So, last time we learned all about the unconstrained spatial interaction model; how we can use it to estimate flows in a system using values for origin emissiveness or destination attractiveness; how we can tweak the estimates the model produces through adjusting either the parameters associated with the predictor variables, or through using different predictor variables or updating their values; and how we can improve the fits of the model further by calibrating the paramaters through using a Poisson regression model.\n",
    "\n",
    "We saw that even after calibration, our model still only explained around 60% of the variation in the flows that we observed in our system, so can we do any better? Well yes, yes we can!\n",
    "\n",
    "First of all however, lets bring some of our work across from the previous practical so that we can get straight to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import folium\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcRSquared(observed, estimated):\n",
    "    \"\"\"Calculate the r^2 from a series of observed and estimated target values\n",
    "    inputs:\n",
    "    Observed: Series of actual observed values\n",
    "    estimated: Series of predicted values\"\"\"\n",
    "    \n",
    "    r, p = scipy.stats.pearsonr(observed, estimated)\n",
    "    R2 = r **2\n",
    "    \n",
    "    return R2\n",
    "\n",
    "def CalcRMSE(observed, estimated):\n",
    "    \"\"\"Calculate Root Mean Square Error between a series of observed and estimated values\n",
    "    inputs:\n",
    "    Observed: Series of actual observed values\n",
    "    estimated: Series of predicted values\"\"\"\n",
    "    \n",
    "    res = (observed -estimated)**2\n",
    "    RMSE = round(sqrt(res.mean()), 3)\n",
    "    \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cdatasub = pd.read_csv(\"Data/cdatasub1.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constrained models\n",
    "\n",
    "If we return to [Alan Wilson's 1971 paper](https://journals.sagepub.com/doi/abs/10.1068/a030001), he introduces a full <i>family</i> of spatial interaction models of which the unconstrained model is just the start. And indeed since then, there have been all number of incremental advances and alternatives (such as [Stewart Fotheringham's Competing Destinations models](https://www.researchgate.net/publication/23537117_A_New_Set_of_Spatial-Interaction_Models_The_Theory_of_Competing_Destinations), [Pooler's production/attractino/cost relaxed models](http://journals.sagepub.com/doi/abs/10.1177/030913259401800102), [Stillwell's origin/destination parameter specific models](http://journals.sagepub.com/doi/pdf/10.1068/a101187) and [mine and Alan's own multi-level model](http://journals.sagepub.com/doi/pdf/10.1068/a45398) (to name just a few).\n",
    "\n",
    "In this session we will explore the rest of Wilson's family - the Production (origin) Constrained Model; the Attraction (destination) Constrained Model; and the Doubly Constrained Model.\n",
    "\n",
    "We will see how we can, again, use a Poisson regression model in Python to calibrate these models and how, once calibrated, we can use the models in different contexts, such as Land Use Transportation Interaction (LUTI) modelling, retail modelling and migration modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Production and Attraction Constrained Models\n",
    "\n",
    "First of all let us extract the results that we got last time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdatasubmat = pd.pivot_table(cdatasub, values =\"TotalNoIntra\", index=\"Orig\", columns = \"Dest\",\n",
    "                            aggfunc=np.sum, margins=True)\n",
    "cdatasubmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wilson's real contribution to the field was in noticing that the unconstrained gravity model was sub-optimal as it did not make use of all of the available data in the system we are studying.\n",
    "\n",
    "If we recall the estimates from our unconstrained model, none of the estimates summed to the observed in and out-flow totals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdatasubmat2 = cdatasub.pivot_table(values =\"unconstrainedEst2\", index=\"Orig\", columns = \"Dest\",\n",
    "                            aggfunc=np.sum, margins=True)\n",
    "cdatasubmat2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our estimates did sum to the grand total of flows, but this is because we were really fitting a 'total constrained' model which used $k$ - our constant of proportionality -  to ensure everything sort of added up (to within 1 commuter).\n",
    "\n",
    "Where we have a full flow matrix to calibrate parameters, we can incorporate the row (origin) totals, column (destination) totals or both origin and destination totals to <i>constrain</i> our flow estimates to these known values.\n",
    "\n",
    "There are various reasons for wanting to do this, for example:\n",
    "\n",
    "1. If we are interested in flows of money into businesses or customers into shops, we might have information on the amount of disposable income and shopping habits of the people living in different areas from loyalty card data. This is known information about our origins and so we could constrain our spatial interaction model to this known information - we can make the assumption that this level of disposable income remains the same. We can then use other information about the attractiveness of places these people might like to shop in (store size, variety / specialism of goods etc.), to estimate how much money a new store opening in the area might make, or if a new out-of-town shopping centre opens, how much it might affect the business of shops in the town centre. This is what is known in the literature as the ‘retail model’ and is perhaps the most common example of a <b>Production (orign) Constrained Spatial Interaction Model</b>.\n",
    "\n",
    "2. We might be interested in understanding the impact of a large new employer in an area on the flows of traffic in the vicinity or on the demand for new worker accommodation nearby. A good example of where this might be the case is with large new infrastructure developments like new airports. For example, before the go-ahead for the new third runway at Heathrow was given, one option being considered was a new runway in the Thames Estuary. If a new airport was built here, what would be the potential impact on transport flows in the area and where might workers commute from? This sort of scenario could be tested with an <b>Attraction (destination) Constrained Spatial Interaction Model</b> where the number of new jobs in a destination is known (as well as jobs in the surrounding area) and the model could be used to estimate where the workers will be drawn from (and their likely travel-to-work patterns). \n",
    "\n",
    "3. We might be interested in understanding the changing patterns of commuting or migration over time. Data from the Census allows us to know an accurate snap-shot of migrating and commuting patterns every 10 years. In these full data matrices, we know both the numbers of commuters/migrants leaving origins and arriving at destinations as well as the interactions between them. If we constrain our model estimates to this known information at origin and destination, we can examine various things, including:\n",
    "    - The ways that the patterns of commuting/migration differ from the model predictions - where we might get more migrant/commuter flows than we would expect.\n",
    "    - How the model parameters vary over time - for example how does distance / cost of travel affect flows over time? Are people prepared to travel further or less far than before?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Production-constrained Model\n",
    "\n",
    "\n",
    "\\begin{equation} \\label{eq:1} \\tag{1}\n",
    "T_{ij} = A_i O_i D_j^\\gamma d_{ij}^{-\\beta}\n",
    "\\end{equation}\n",
    "\n",
    "Where\n",
    "\n",
    "\\begin{equation} \\label{eq:2} \\tag{2}\n",
    "O_i = \\sum_j T_{ij}\n",
    "\\end{equation}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{equation} \\label{eq:3} \\tag{3}\n",
    "A_i = \\frac{1}{\\sum_j D_j^\\gamma d_{ij}^{-\\beta}}\n",
    "\\end{equation}\n",
    "\n",
    "In the production-constrained model, $O_i$ does not have a parameter as it is a known constraint. $A_i$ is known as a <i>balancing factor</i> and is a vector of values which relate to each origin, $i$, which do the equivalent job to $k$ in the unconstrained/total constrained model but ensure that flow estimates from each origin sum to the known totals, $O_i$ rather than just the overall total.\n",
    "\n",
    "Now at this point, we could calculate all of the $O_i$s and $A_i$s by hand for our sample system and then set about guessing/estimating the parameter values for the rest of the model, but as you might have already suspected from last time, we can use Python and `glm` to make it really easy and do all of that for us -woo hoo!\n",
    "\n",
    "We set about re-specifying the Production Constrained model as a Poisson regression model in exactly the same way as we did before. We need to take logs of the right-hand side of the equation and assume that these are logarithmically linked to the Poisson distributed mean ($\\lambda_{ij}$) of the $T_{ij}$ variable. As such, Equation (1) becomes:\n",
    "\n",
    "\\begin{equation} \\label{eq:4} \\tag{4}\n",
    "\\lambda_{ij} = \\exp (\\alpha_i + \\gamma \\ln D_j - \\beta \\ln d_{ij})\n",
    "\\end{equation}\n",
    "\n",
    "In Equation (4) $\\alpha_i$ is the equivalent of the vector of balancing factors $A_i$, but in regression /log-linear modelling terminology can also be described as either <b>dummy variables</b> or <b>fixed effects</b>. In practical terms, what this means is that in our regression model, $\\alpha_i$ is modelled as a [categorical predictor](https://en.wikipedia.org/wiki/Categorical_variable) and therefore in the Poisson regression model, we don't use the numeric values of $O_i$, we can use a categorical identifier for the origin. In terms of the example table above, for Barking and Dagenham we wouldn't use 5675 as we would if we were fitting Equation (1), we would just used 'Barking and Dagenham'.\n",
    "\n",
    "So, let's give this model a whirl..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the formula (the \"-1\" indicates no intercept in the regression model).\n",
    "formula = 'Total ~ OrigCodeNew + log_Dj2_destsal + log_Dist-1'\n",
    "#run a production constrained sim\n",
    "prodSim = smf.glm(formula = formula, data=cdatasub, family=sm.families.Poisson()).fit()\n",
    "#let's have a look at it's summary\n",
    "print(prodSim.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what do we have?\n",
    "\n",
    "Well, there are the elements of the model output that should be familiar from the unconstrained model:\n",
    "\n",
    "The $\\gamma$ parameter related to the destination attractiveness: 2.0440\n",
    "\n",
    "The $\\beta$ distance decay parameter: 2.2140. Recall the negative sign in the equation.\n",
    "\n",
    "We can see from the standard outputs from the model that all of the explanatory variables are statistically significant (P>|z| < 0.01) and the z-scores indicate that the destination salary is having the most influence on the model, with distance following closely behind. And then we have a series of paramaters which are the vector of $\\alpha_i$ values associated with our origin constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Model Estimates\n",
    "\n",
    "Now at this point you will be wanting to know what effect the constraints have had on the estimates produced by the model, so let's plug the parameters back into Equation 4 and take a look...\n",
    "\n",
    "Create some $O_i$ and $D_j$ columns and store the total in and out flow matrix margins in them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create some Oi and Dj columns in the dataframe and store row and column totals in them:\n",
    "#to create O_i, take cdatasub ...then... group by origcodenew ...then... summarise by calculating the sum of Total\n",
    "O_i = pd.DataFrame(cdatasub.groupby([\"OrigCodeNew\"])[\"Total\"].agg(np.sum))\n",
    "O_i.rename(columns={\"Total\":\"O_i\"}, inplace = True)\n",
    "cdatasub = cdatasub.merge(O_i, on = \"OrigCodeNew\", how = \"left\" )\n",
    "\n",
    "D_j = pd.DataFrame(cdatasub.groupby([\"DestCodeNew\"])[\"Total\"].agg(np.sum))\n",
    "D_j.rename(columns={\"Total\":\"D_j\"}, inplace = True)\n",
    "cdatasub = cdatasub.merge(D_j, on = \"DestCodeNew\", how = \"left\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to fish the coefficients out of the prodSim glm object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can do this by pulling out the parameter values\n",
    "coefs = pd.DataFrame(prodSim.params)\n",
    "coefs.reset_index(inplace=True)\n",
    "coefs.rename(columns = {0:\"alpha_i\", \"index\":\"coef\"}, inplace = True)\n",
    "to_repl = [\"(OrigCodeNew)\", \"\\[\", \"\\]\"]\n",
    "for x in to_repl:\n",
    "    coefs[\"coef\"] = coefs[\"coef\"].str.replace(x, \"\")\n",
    "#then once you have done this you can join them back into the dataframes\n",
    "cdatasub = cdatasub.merge(coefs, left_on=\"OrigCodeNew\", right_on=\"coef\", how = \"left\")\n",
    "cdatasub.drop(columns = [\"coef\"], inplace = True)\n",
    "#check this has worked\n",
    "cdatasub.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now we can save our parameter values into some variables... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_i = prodSim.params[0:7]\n",
    "gamma = prodSim.params[7]\n",
    "beta = -prodSim.params[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're ready to generate our estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdatasub[\"prodsimest1\"] = np.exp(cdatasub[\"alpha_i\"]+gamma*cdatasub[\"log_Dj2_destsal\"] \n",
    "                                 - beta*cdatasub[\"log_Dist\"])\n",
    "#or you could do it the easy way like we did last week with the fitted column (See previous practical)\n",
    "cdatasub.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Assessing the model output\n",
    "\n",
    "So what do the outputs from our Production Constrained Model look like? How has the goodness-of-fit improved and how can we start to use this a bit like a retail model and assess the likley impacts of changing detsination attractiveness etc.?\n",
    "\n",
    "### 2.2.1 The flow matrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first round the estimates\n",
    "cdatasub[\"prodsimest1\"] = round(cdatasub[\"prodsimest1\"],0)\n",
    "#now we can create a pivot tabel to turn the paired list into a matrix, and compute the margins as well\n",
    "cdatasubmat3 = cdatasub.pivot_table(values =\"prodsimest1\", index=\"Orig\", columns = \"Dest\",\n",
    "                            aggfunc=np.sum, margins=True)\n",
    "cdatasubmat3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compared with the original observed data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdatasubmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is very easy to see the Origin Constrained working. The sum across all destinations for each origin in the estimated matrix is exactly the same sum (give or take 1 or 2) across the observed matrics - $\\sum_j T_{ij} = \\sum_j \\lambda_{ij} = O_i$, but clearly, the same is not true when you sum across all origins for each destination - $\\sum_i T_{ij} \\neq \\sum_i \\lambda_{ij} \\neq D_j$\n",
    "\n",
    "### 2.2.2 How do the fits compare with the unconstrained model from last time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CalcRSquared(cdatasub[\"Total\"], cdatasub[\"prodsimest1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CalcRMSE(cdatasub[\"Total\"], cdatasub[\"prodsimest1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly by constraining our model estimates to known origin totals, the fit of the model has improved quite considerably - from around 0.67 in the unconstrained model to around 0.81 in this model. The RMSE has also dropped quite noticeably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 A 'what if...' scenario\n",
    "\n",
    "Now that have have calibrated our parameters and produced some estimates, we can start to play around with some what-if scenarios.\n",
    "\n",
    "For example, What if the government invested loads of money into a new Car Plant in Barking and Dagenham and as a result, average wages increased from £16,200 to £25,000. \n",
    "\n",
    "First create a new variable with these altered salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_sal(row):\n",
    "    if row[\"DestCodeNew\"] == \"E09000002\":\n",
    "        val = 25000\n",
    "    else:\n",
    "        val = row[\"Dj2_destsal\"]\n",
    "    return val\n",
    "        \n",
    "cdatasub[\"Dj3_destsalScenario\"] = cdatasub.apply(new_sal, axis =1)\n",
    "cdatasub.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plug these new values into the model and see how this changes the flows in the system ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdatasub[\"prodsimest2\"] = np.exp(cdatasub[\"alpha_i\"]+gamma*np.log(cdatasub[\"Dj3_destsalScenario\"]) - beta*cdatasub[\"log_Dist\"])\n",
    "\n",
    "cdatasub[\"prodsimest2\"] = round(cdatasub[\"prodsimest2\"],0)\n",
    "#now we can convert the pivot table into a matrix\n",
    "cdatasubmat4 = cdatasub.pivot_table(values =\"prodsimest2\", index=\"Orig\", columns = \"Dest\",\n",
    "                            aggfunc=np.sum, margins=True)\n",
    "cdatasubmat4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that by increasing the average salary in Barking and Dagenham, we’ve increased flows into Barking and Dagenham, but have not reduced the flows into other zones - the original constraints are still working on the other zones. One way to get around this, now that we have calibrated our parameters, is to return to the multiplicative model in Equation 1 and run this model after calculating our own $A_i$ balancing factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate some new wj^alpha and d_ij^beta values\n",
    "Dj2_gamma = cdatasub[\"Dj2_destsal\"]**gamma\n",
    "dist_beta = cdatasub[\"Dist\"]**beta\n",
    "#calcualte the first stage of the Ai values\n",
    "cdatasub[\"Ai1\"] = Dj2_gamma * dist_beta\n",
    "#now do the sum over all js bit\n",
    "A_i = pd.DataFrame(cdatasub.groupby([\"OrigCodeNew\"])[\"Ai1\"].agg(np.sum))\n",
    "#now divide into 1\n",
    "A_i[\"Ai1\"] = 1/A_i[\"Ai1\"]\n",
    "A_i.rename(columns={\"Ai1\":\"A_i\"}, inplace=True)\n",
    "#and write the A_i values back into the dataframe\n",
    "cdatasub = cdatasub.merge(A_i, left_on=\"OrigCodeNew\", right_index=True, how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that is it for calculating your $A_i$ values. Now you have these, it’s very simple to plug everything back into Equation 1 and generate some estimates…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#to check everything works, recreate the original estimates\n",
    "cdatasub[\"prodsimest3\"] = cdatasub[\"A_i\"]*cdatasub[\"O_i\"]*Dj2_gamma*dist_beta\n",
    "#round\n",
    "cdatasub[\"prodsimest3\"] = round(cdatasub[\"prodsimest3\"])\n",
    "#check\n",
    "cdatasub[[\"prodsimest1\", \"prodsimest3\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that your new estimates are exactly the same as your first estimates. If they’re not, then something has gone wrong. Now we have this though, we can keep messing around with some new estimates and keep the constraints. Remember, though, that you will need to recalculate $A_i$ each time you want to create a new set of estimates. Let’s try with our new values for the destination salary in Barking and Dagenham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate some new wj^alpha and d_ij^beta values\n",
    "Dj3_gamma = cdatasub[\"Dj3_destsalScenario\"]**gamma\n",
    "#calcualte the first stage of the Ai values\n",
    "cdatasub[\"Ai1\"] = Dj3_gamma * dist_beta\n",
    "#now do the sum over all js bit\n",
    "A_i = pd.DataFrame(cdatasub.groupby([\"OrigCodeNew\"])[\"Ai1\"].agg(np.sum))\n",
    "#now divide into 1\n",
    "A_i[\"Ai1\"] = 1/A_i[\"Ai1\"]\n",
    "A_i.rename(columns={\"Ai1\":\"A_i2\"}, inplace=True)\n",
    "#and write the A_i values back into the dataframe\n",
    "cdatasub = cdatasub.merge(A_i, left_on=\"OrigCodeNew\", right_index=True, how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have some new $A_i$'s, let's generate some new scenario flow estimates..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check everything works, recreate the original estimates\n",
    "cdatasub[\"prodsimest4\"] = cdatasub[\"A_i2\"]*cdatasub[\"O_i\"]*Dj3_gamma*dist_beta\n",
    "#round\n",
    "cdatasub[\"prodsimest4\"] = round(cdatasub[\"prodsimest4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdatasubmat5 = cdatasub.pivot_table(values =\"prodsimest4\", index=\"Orig\", columns = \"Dest\",\n",
    "                            aggfunc=np.sum, margins=True)\n",
    "cdatasubmat5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of things to note here. Firstly, flows into Barking and Dagenham have virtually doubled, while flows into other Boroughs have reduced.\n",
    "\n",
    "Secondly, Barking and Dagenham was a poor estimate anyway - it model was very much over estimating flows into this Borough. Increasing the salary into this borough has significantly increased flows, so this indicates that there are probably lots of other things that might be discouraging people from working in this borough.\n",
    "\n",
    "Thirdly, Our origin constraints are now holding again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Attraction-Constrained Model\n",
    "\n",
    "The attraction constrained model is virtually the same as the PRoduction constrained model:\n",
    "\n",
    "\\begin{equation} \\label{eq:5} \\tag{5}\n",
    "T_ij = D_j B_j O_i^\\alpha d_{ij}^{-\\beta}\n",
    "\\end{equation}\n",
    "\n",
    "Where\n",
    "\n",
    "\\begin{equation} \\label{eq:6} \\tag{6}\n",
    "D_j = \\sum_i T_{ij}\n",
    "\\end{equation}\n",
    "\n",
    "and \n",
    "\n",
    "\\begin{equation} \\label{eq:7} \\tag{7}\n",
    "B_j = \\frac{1}{\\sum_i O_i^\\alpha d_{ij}^{-\\beta}}\n",
    "\\end{equation}\n",
    "\n",
    "I won't dwell on the attraction constrained model, except to say that it can be run in Python as you would expect:\n",
    "\n",
    "\\begin{equation} \\label{eq:8} \\tag{8}\n",
    "\\lambda_{ij} \\exp (\\alpha \\ln O_i + \\gamma_i - \\beta \\ln d_{ij})\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the formula (the \"-1\" indicates no intercept in the regression model).\n",
    "attr_form = 'Total ~ DestCodeNew + log_Oi1_origpop + log_Dist-1'\n",
    "#run a production constrained sim\n",
    "attrSim = smf.glm(formula = attr_form, data=cdatasub, family=sm.families.Poisson()).fit()\n",
    "#let's have a look at it's summary\n",
    "print(attrSim.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine how the constraints hold for destinations this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the predictions\n",
    "predictions = attrSim.get_prediction(cdatasub[[\"DestCodeNew\", \"log_Oi1_origpop\", \"log_Dist\"]])\n",
    "predictions_summary_frame = predictions.summary_frame()\n",
    "cdatasub[\"attrsimFitted\"] = round(predictions_summary_frame[\"mean\"],0)\n",
    "#now we can create pivot table to turn paired list into matrix (and compute the margins as well)\n",
    "cdatasubmat6 = cdatasub.pivot_table(values =\"attrsimFitted\", index=\"Orig\", columns = \"Dest\",\n",
    "                                    aggfunc=np.sum, margins=True)\n",
    "cdatasubmat6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdatasubmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we can test the goodness-of-fit in exactly the same way as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CalcRSquared(cdatasub[\"Total\"], cdatasub[\"attrsimFitted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CalcRMSE(cdatasub[\"Total\"], cdatasub[\"attrsimFitted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that’s where I’ll leave singly constrained models for now. There are, of course, plenty of things you could try out. For example:\n",
    "\n",
    "1. You could try mapping the coefficients or the residual values from the model to see if there is any patterning in either the over or under prediction of flows.\n",
    "\n",
    "\n",
    "2. You could try running your own version of a LUTI model by first calibrating the model parameters and plugging these into a multiplicative version of the model, adjusting the destination constraints to see which origins are likely to generate more trips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge to complete\n",
    "\n",
    "It is recommended that you complete this challenge to show that you understand the purpose of this model and how it can be used.\n",
    "\n",
    "Just like we did for the origin constrained model, we can try to see the effects of the model in response to a changes in a what-if scenario. In this case, instead of the origin constrained model we are going to be working with the destination constrained model whereby we can check to see the effects on the model of an increase in housing units in Bromley increasing population from 164,000 to 200,000 (as if we could ever build that many that fast).\n",
    "\n",
    "First, we create a new variable with these altered populations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new pop function to change the value with\n",
    "#OrigCodeNew == \"E09000006\" to 200_000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#create a variable called Oi2_origpop_scenario while applying the new_pop function\n",
    "\n",
    "\n",
    "#check the result to make sure it has been applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can plug the new values into a model, we need extract the coefficients from the attraction based model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a coefficients dataframe from the attrSim model\n",
    "\n",
    "\n",
    "#call the coefficients Beta_j\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the unnecessary DestCodeNew and [] in the\n",
    "#coefficients column of the coefs DataFrame\n",
    "\n",
    "    \n",
    "#then once you have done this you can join them back into the dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract alpha and beta from the\n",
    "#attrSim model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use these coefficients to calculate an estimate for the flows in the system using the new population measures but with the existing paramater values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create estimate for attrsimest2\n",
    "#using the calculated Beta_j and alpha and beta values\n",
    "#remember to log the new origin population\n",
    "\n",
    "\n",
    "\n",
    "#round these to integer values\n",
    "#as we don't want half a person\n",
    "\n",
    "#now we can convert the pivot table into a matrix\n",
    "#called cdatasubmat7\n",
    "\n",
    "\n",
    "#display the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that increasing the population in Bromley, we've increased flows from Bromley, but we did not reduce the flows coming from the other zones to allow the destination constraints to hold. We then need to return to the attraction constrained equation and run the model after calculating our own $\\Beta_j$ balancing factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate some new Oi^alpha and d_ij^beta values\n",
    "#called oi2_alpha and dist_beta\n",
    "\n",
    "\n",
    "#calcualte the first stage of the Bj values\n",
    "\n",
    "#now do the sum over all is bit\n",
    "\n",
    "#now divide into 1\n",
    "\n",
    "#rename the column from Bj1 to B_j\n",
    "\n",
    "#and write the B_j values back into the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plug everything back into Equation 5 and generate some estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check that everything works, recreate the original estimates\n",
    "#using equation 5 above and assign to attrsimest3\n",
    "\n",
    "\n",
    "#round\n",
    "\n",
    "#check the head of the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that the new estimates are exactly the same as the first estimates (i.e. attrsimFitted should be equal to attrsimest3). If they are not then something has gone wrong. Now we have this though, we keep messing around with some new estimates and keep the constraints. As before, in calculating new estimates you need to recaclulate $\\Beta_j$ each time. We can try with our new population estimate for Bromley:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate some new O_i^alpha \n",
    "#call it Oi3_alpha\n",
    "\n",
    "#calculate the first stage of the Bj values\n",
    "\n",
    "#now do the sum over all is bit\n",
    "\n",
    "#now divide into 1\n",
    "\n",
    "#rename the column\n",
    "\n",
    "#and write the B_j values back into the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check everything works create the estimates for attrsimest4\n",
    "\n",
    "#round to integer values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the results in a pivot table of attrsimest4\n",
    "#called cdatasubmat8\n",
    "\n",
    "\n",
    "#show the matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare this to the actual flows\n",
    "cdatasubmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have the results what do these mean. \n",
    "- Where have flows from dropped? \n",
    "- Where have flows increased from?\n",
    "- Which flow was most affected? \n",
    "- Why do you think that is? \n",
    "- Is the attraction constrained model appropriate?\n",
    "- Would jobs respond to the increase in households, or would it be the other way round?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbsim",
   "language": "python",
   "name": "urbsim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
